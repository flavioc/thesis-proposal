In this chapter we want to present some preliminary results of the \lang runtime system.
Firstly, we want to show that our virtual machine performs well when running multiple threads,
i.e., it can reasonably schedule the execution of programs to reduce execution time and increase parallel speedup. Secondly, we want to show that by using coordination directives, programs can perform faster.
Finally, we want to show that our programs are usually shorter than programs written in other languages.  

In our experimental setup, we used a machine with
four AMD Six-Core Opteron TM 8425 HE (2100 MHz) chips (24 cores) and 64 GB of DDR-2 667MHz (16x4GB) RAM,
     running GNU/Linux (kernel 2.6.31.5-127 64 bits).
     We compiled our virtual machine using GCC 4.4.5 (g++) with the flags \texttt{-O3 -std=c+0x -march=x86-64}.
     We run all experiments 3 times with the same configuration and then we averaged the run time.

\section{Parallel Experiments}

For the parallel results, we run each program using 1, 2, 4, 6, 8, 10, 12, 14 and 16 threads and compared the runtime against the execution of the sequential version of the virtual machine. We used the following programs:

\newcommand{\figsize}[0]{6.5cm}
\captionsetup[sub]{              % The subcaption settings
       font=scriptsize}

\begin{description}
   \item[Greedy Graph Coloring (GGC)] in this program, we attempt to color each node of a graph so that no two adjacent nodes have the same color. We start with a small number of colors and then we expand the number of colors when we cannot color the graph.
   \item[PageRank] implements an asynchronous PageRank algorithm without synchronization between iterations. Every time a node sends a new rank to its neighbors and the change was significant, the neighbors are scheduled to recompute their ranks.
   \item[N queens] already explained before. We use an 13x13 board.
\end{description}

Figure~\ref{exp:graph_coloring} presents the speedup results for the GGC program using 2 different datasets. In the first plot, we show the speedup for a graph of 12,000 webpages. Since this dataset follows the power law, that is, there is a small number of pages with a lots of links (1\% of the nodes have 75\% of the edges), the speedup is slightly worse than the one shown when using a random dataset of 2,000 nodes, where each node has more or less the same number of links.


\begin{figure*}[hp]
   \centering
   \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{new-benchmarks/speedup_greedy-graph-coloring-search_engines.pdf}
      \caption{Search engine, a graph of web pages collected from a search engine (around 12,000 nodes).}
   \end{subfigure}
   \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{new-benchmarks/speedup_greedy-graph-coloring-2000.pdf}
      \caption{Using a random graph with 2,000 nodes.\newline}
   \end{subfigure}
   \caption{Experimental results for the greedy GGC algorithm.}
   \label{exp:graph_coloring}
\end{figure*}

The PageRank results are shown in Fig.~\ref{exp:pagerank}. We used the same search engine dataset as before and a new dataset representing movie websites \footnote{The search engine graph was retrieved from \url{http://www.cs.toronto.edu/~tsap/experiments/download/download.html}}.
For the second plot, we used a random graph with 5000 nodes and 500,000 edges. Although the search engine graph has half the edges (around 250,000), it scales better than the random graph, meaning that the PageRank program depends on the number of nodes to be more scalable.

\begin{figure*}[hp]
   \centering
   \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{new-benchmarks/speedup_pagerank-search_engines.pdf}
      \caption{Search engine, a graph of web pages collected from a search engine (around 12,000 nodes)}
   \end{subfigure}
   \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{new-benchmarks/speedup_pagerank-5000.pdf}
      \caption{Using a random graph with 5,000 nodes.\newline}
   \end{subfigure}
   \caption{Experimental results for the asynchronous PageRank algorithm.}
   \label{exp:pagerank}
\end{figure*}

\begin{figure}[h!]
     \centering
    \includegraphics[width=0.4\textwidth]{new-benchmarks/speedup_8queens-13.pdf}
    \caption{Experimental results for the N queens program (13x13~board).}
    \label{exp:8queens}
\end{figure}

The results for the N queens program are shown in Fig.~\ref{exp:8queens}. The program is not regular since computation starts at the top of the grid and then rolls down, until only the last row is doing computation. Note that as the computation goes from row to row, the number of states increase, creating even more imbalances. The results show that our system is able to scale well with more traditional algorithms such as N Queens.

\section{Coordination Experiments}

In our coordination experiments, we are interested in showing that coordination improves the execution time of programs.
To do that, we used the following 3 programs:

\begin{description}
   \item[Heat Transfer] in the heat transfer program, we have a grid of cells that transfer heat with the neighbor cells by taking into account the edge weights. We use a dataset with a square of cells in the center of the grid with very high heat, while the outer cells have low heat. We use coordination to prioritize the neighbors of cells where rapid heat changes happen.
   \item[Single Source Shortest Path (SSSP)] we use the SSSP program shown earlier but we extended it to compute the distance to several nodes in order to increase the amount of computation.
   \item[Belief Propagation (BP)] this is the belief propagation program explained before. We build splash trees to improve performance.
\end{description}

Fig.~\ref{exp:heat-transfer} shows the results for the heat transfer program. \textbf{Threads} represents the speedup of the multicore execution
without coordination, while \textbf{Coord} represents the speedup when using coordination directives.
Both execution modes were compared against the sequential execution without coordination.
When using 1 thread, the coordinated version is 1.5 times
faster, however the advantage completely disappears as more threads are added. This happens because the \textbf{set-priority} action fact is ignored
when it is sent to a node located in a different thread. Also, the cost of scheduling is too large when compared to the short time spent
updating the heat value.

\begin{figure}[h!]
     \centering
   \begin{subfigure}[b]{0.4\textwidth}
      \includegraphics[width=\textwidth]{new-benchmarks/speedup_new-heat-transfer-80.pdf}
      \caption{Heat transfer program.}\label{exp:heat-transfer}
   \end{subfigure}
   \begin{subfigure}[b]{0.4\textwidth}
      \includegraphics[width=\textwidth]{new-benchmarks/speedup_shortest-uspowergrid.pdf}
      \caption{SSSP program with the US Power Grid dataset.}\label{exp:sssp-uspowergrid}
   \end{subfigure}
   \caption{Experimental results for the HT and SSSP programs when using coordination.}
\end{figure}

To measure the performance of the SSSP program we used several datasets retrieved from \url{http://toreopsahl.com/datasets}. We computed several
statistics about each dataset, including: the number of nodes (\textbf{\# Nodes}), the number of edges (\textbf{\# Edges}) and
the average number of edges per node (\textbf{Edges / Node}). We also sorted the nodes by number of edges and counted the top number of nodes
with 25\% (\textbf{25\% Edges}), 50\% (\textbf{50\% Edges}) and 75\% (\textbf{75\% Edges}) of all edges.
These statistics and the speedup (\textbf{Speedup}) when using the coordinated version with 1 thread are presented in Table~\ref{tbl:shortest_path_speedup}.

We have tried to understand if there is a correlation between the graph structure and the coordination speedup. We can see that a higher number
of nodes and edges tends to improve execution. The US Airports dataset stands out because it is a small sized graph where a subset of airports
(70) have most connections. The other smaller datasets have a much uniform distribution.
Still, the coordinated execution for most datasets is, on average, around 30\% faster than the regular execution. We also included the speedup plot
for the US Power Grid dataset in Fig.~\ref{exp:sssp-uspowergrid} that compares the regular version against the coordinated version.
We note that the coordinated version loses its advantages as the number of threads increase. This happens because we do not
currently use action facts that are sent between nodes in different threads.

\begin{table*}[ht]

\begin{center}
   \resizebox{16.5cm}{!}{
    \begin{tabular}{| l | c | c | c | c | c | c | c |}
    \hline
    \textbf{Dataset} & \textbf{Speedup} & \textbf{\# Nodes} & \textbf{\# Edges} & \textbf{Edges / Node} & \textbf{25\% Edges} & \textbf{50\% Edges} & \textbf{75\% Edges} \\ \hline \hline
    500 US Airports & 1.630 & 500 & 5960 & 11.92 & 14 & 37 & 70 \\ \hline
    US Power Grid & 1.425 & 4941 & 13188 & 2.67 & 485 & 1374 & 2131 \\ \hline
    Celegans Neural Network & 1.122 & 297 & 2345 & 7.89 & 24 & 65 & 104 \\ \hline
    Facebook like social network & 1.532 & 1899 & 20296 & 10.68 & 42 & 150 & 273 \\ \hline
    Intra-organizational network & 1.120 & 77 & 2288 & 28.94 & 9 & 24 & 36 \\ \hline
    \end{tabular}}
\end{center}
     \caption{Summarized information about the datasets used in the SSSP program.}
     \label{tbl:shortest_path_speedup}
\end{table*}

For the BP program, we have a noisy image made of 400x400 pixels that needs to be de-noised.
To put our implementation in perspective, we have also run the GraphLab (version 1) implementation of the same problem. The results are shown
in Fig.~\ref{exp:splashbp}. The first plot presents the scalability results for the simple BP problem. The GraphLab version
uses the \textbf{fifo} scheduler that works identically to the basic \lang scheduler.

\begin{figure*}[ht]
   \centering
   \begin{subfigure}[b]{0.3\textwidth}
      \includegraphics[width=\textwidth]{new-benchmarks/speedup_bp-graphlab-400.pdf}
      \caption{Scalability of basic BP.\newline}
   \end{subfigure}
   \begin{subfigure}[b]{0.3\textwidth}
      \includegraphics[width=\textwidth]{new-benchmarks/speedup2_bp-graphlab-400.pdf}
      \caption{Scalability of BP with splashes.\newline}
   \end{subfigure}
   \begin{subfigure}[b]{0.3\textwidth}
      \includegraphics[width=\textwidth]{new-benchmarks/improv_bp-graphlab-400.pdf}
      \caption{Coordination improvements by using splashes.}
   \end{subfigure}
   \caption{Experimental results for BP with coordination using splashes. The dataset is a 400x400 image.}
   \label{exp:splashbp}
\end{figure*}

The plot in Fig.~\ref{exp:splashbp}~(b) shows the scalability of the coordinated version. For GraphLab we used the \textbf{splash} scheduler, while \lang
runs with the extra coordination rules. Again, the scalability lines are very similar, but GraphLab appears to be slightly more scalable.
Finally, the last plot (Fig.~\ref{exp:splashbp}~(c)) presents the improvements of the coordinated version over the basic version.
With only 1 thread, we get almost a 3-fold speedup over the version without coordination. We can also see that adding more threads tends to reduce the effectiveness of splash trees in both systems.

In summary, using a small set of action facts and derivation rules we were able to implement complex
scheduling strategies similar to the ones present in GraphLab, a practical and powerful machine learning
framework.

\section{Language expressiveness and conciseness}

Finally, we show some results comparing the size of \lang programs against implementations of the same
programs in other languages. We want to show that \lang programs are more concise and can also be run in parallel from the start.

In table~\ref{tbl:length} we show how \lang programs compare against programs written in other languages in
terms of size. For the SSSP and the C version of N Queens~\cite{8queens-parallel} we are considering sequential implementations
that are very difficult to parallelize. Even so, \lang programs are much smaller and in our opinion, easier
to understand. For the N Queens problem, we also included an MPI implementation written in C~\cite{Rolfe:2008:SMA:1473195.1473217}
that is around 10 times longer than the \lang version. We are currently developing an MPI version
of the \lang runtime and preliminary results, also show some good speedups for this program.

\begin{table}[ht]
\begin{center}
   \resizebox{12cm}{!}{
    \begin{tabular}{| c | c | l | c |}
    \hline
    \textbf{Program} & \textbf{\lang} & \textbf{Others} & \textbf{Average} \\ \hline \hline
    SSSP & 6 & 25 (C++) & 24\% \\ \hline
    PageRank & 30 & 60 (GraphLab) & 50\% \\ \hline
    BP & 50 & 90 (GraphLab) & 55\% \\ \hline
    Splash BP & 50 & 350 (GraphLab) & 14\% \\ \hline
    N Queens & 40 & 300 (C~\cite{8queens-parallel}), 400 (MPI~\cite{Rolfe:2008:SMA:1473195.1473217}) & 11\% \\ \hline
    \end{tabular}}
\end{center}
     \caption{Comparison of source code size against other languages.}
     \label{tbl:length}
\end{table}

The GraphLab versions of PageRank, BP and Splash BP are all written in C++ and can be run in
parallel. We only counted the bare minimum number of lines for these programs (the update function)
so that our analysis is not biased towards \lang. The \lang versions of PageRank and BP are around
half of the size of the GraphLab versions. However, \lang really shines in the Splash BP program because
the code is much more concise than the corresponding code of GraphLab.

\section{Comparison Against Other Systems}

We also made some absolute runtime comparisons of \lang programs with the same programs written in
other languages such as Prolog, Python and C/C++.

In our experiments, the N Queens program runs more than 20 times slower when compared to a sequential C implementation and is two times faster than a Python
implementation. The PageRank algorithm runs around 5 to 6 times slower than the identical GraphLab
implementation and the SSSP program runs 60 times slower than the sequential C version.

Previously, we have seen that the \lang version of Splash BP program has the same scalability pattern
as GraphLab (Fig.~\ref{exp:splashbp}), however our experiments show that \lang runs about 1.7 times slower in absolute terms.
This is better than the other comparisons and can be explained by the fact
that most computation is done inside external C functions and not applying rules.

We can see a correlation between the number of rules applied and facts derived and execution time.
Because our virtual machine is still a work in progress, we can see some optimization opportunities
to improve these results.

\section{Summary}

This section gave some evidence to our thesis that \lang programs are concise and scalable. Moreover, we
also showed that coordination directives have potential to improve the execution time
of programs. Our coordination code is also far shorter than competing systems such as GraphLab, which is
very promising.
