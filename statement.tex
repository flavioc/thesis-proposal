
We propose LM, a new linear logic programming language designed
to efficiently execute and scale parallel graph based programs on multicore architectures.
We argue that LM is a suitable declarative programming model and that the logical foundations
of LM can be leveraged to make programs more expressive and faster to execute when compared to implementations
in other declarative languages.
We will prove our thesis through five major goals:

\begin{itemize}
   
   \item Linear Logic (mostly done)

   We integrated linear logic~\cite{Girard95logic:its} into our language, so that program state
   can be encoded naturally. The original Meld was fully based on classical logic where everything that
   is derived is true forever. Linear logic turns some facts into resources that will be consumed when a rule is applied.
   We can leverage this sound logical foundation to prove many properties about our programs, including correctness and termination.
   To the best of our knowledge, \lang is the first
   linear logic based language implementation that attempts to solve real world problems.

   \item Coordination (partly done)
   
   LM offers execution control to the programmer through the use of coordination directives to make the program
   faster and more scalable. These coordination
   directives change how the runtime system schedules computation and can be written with the same
   facilities used to write standard program code.
   We are using the concept of \emph{action facts} to coordinate the execution of programs.
   We can increase the priority of certain nodes during runtime according to the state of the
   computation and to the state of the runtime in order to make better scheduling decisions
   so that programs can run faster.
   For example, consider the shortest path program. We can pick nodes with shorter
   distances to the source node before other nodes, so that convergence is reached faster.
   We also use action facts to model output and to visualize the program's behavior in the
   interfaces that we have built. We intend to add more coordination directives and action facts
   and also write more programs that can take advantage of coordination.

   \item Fast Sequential Execution (partly done)
   
   Since LM uses logical rules to perform computation, many program optimizations are possible. The use of linear logic
   opens new opportunities for code improvement since linear logic has some similarities with imperative programming.
   We have already explored some potential optimizations in our implementation, including detecting cases where a fact
   is re-derived with modified arguments. We intend to explore further optimizations, including whole-program optimizations.
   
   \item Multicore Parallelism (partly done)
   
   We divide the logical facts across all the nodes of the graph. Since the
   logical rules only make use of data local to a node, computation can be performed at the
   node level, without reference from other nodes of the graph. We envision the application as
   a communicating graph data structure where each processing unit performs work on a different subset of the graph,
   thus creating parallelism. This is an advantage of LM since we can run programs on many different types
   of distributed systems as long as the underlying runtime system uses the appropriate communication facilities.

   \item Experimental Results (partly done)

   We have implemented a new compiler and a virtual machine prototype from scratch that executes on multicore machines\footnote{Source code is available at \url{http://github.com/flavioc/meld} (virtual machine) and \url{http://github.com/flavioc/cl-meld} (compiler).}.
   We have implemented programs such as belief propagation~\cite{Gonzalez+al:aistats09paraml},
   belief propagation with residual splash~\cite{Gonzalez+al:aistats09paraml}, PageRank~\cite{Page:2001:MNR},
   graph coloring~\cite{PSP:2032868}, N queens~\cite{8queens}, shortest path~\cite{Dijkstra}, diameter estimation~\cite{5234320}, MapReduce~\cite{Dean:2008:MSD:1327452.1327492}, game of life, quick-sort, neural network training, among others.
   Our preliminary results show that our particular implementation makes programs scalable with up to 16 threads. We intend to
   further improve the scalability of our virtual machine.
   
\end{itemize}
