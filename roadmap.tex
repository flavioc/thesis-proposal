
In this chapter we propose a research roadmap that will allow us to fully establish the validity of our thesis.
Our experimental results have shown promising results, although there is still some work to be done to make
\lang more usable in real world applications.

\section{First Major Goal: Improved Coordination Mechanisms}

As we have seen in Chapter~\ref{chapter:exp}, \lang is able to scale programs reasonably well
in multicore architectures.
The use of coordination directives also showed potential to improve the execution time of programs, although it was less impressive
when adding more threads to the system. Therefore, our first major goal for the rest of this thesis is to improve the
efficiency of coordination directives and associated coordination code.

A critical issue in our implementation is the fact that no coordination information is shared between threads. We need to devise a fast mechanism to share coordination directives
in order to reduce the costs associated with scheduling node execution.
Currently, we use an heap data structure to manage nodes with priorities. This data structure is not the most scalable since it is difficult to parallelize its operations.
A more scalable approach may be the skip list data structure~\cite{Sundell:2005:FLC:1073765.1073770}.

We want to implement more programs that use coordination. By implementing new programs we can
extend the set of coordination directives and find out which action or sensing facts may be
appropriate in our system. We are specially interested in designing more sensing and action
facts that place nodes in specific threads to improve data locality.
For instance, some multicore architectures employ a cache hierarchy where cores are clustered,
therefore some pairs of clusters will communicate faster. It might be a good idea to give the programmer
access to the graph of processing units or allow a processing unit to be placed on certain
cores in order to improve computation time.

A potential algorithm that we can implement is the Alpha-Beta search algorithm
that allows us to reduce the search space by prioritizing certain tree branches. However, it remains to be
seen if the program can be easily implemented in \lang.
We intend to measure the execution speedup of these new coordinated programs.

\section{Second Major Goal: Improved parallelism}

Our second goal is to improve the overall scalability of the system. We have tried running our programs with up to 32 threads and we've seen
some scalability problems. To accomplish this, we first need to understand how
threads communicate, specially in terms of node stealing and load balancing.

While the current virtual machine shows good scalability, there is still room for improvement. First,
it should be possible for other threads to immediately update the set of candidate rules when a fact
is sent to a node in another thread. This will increase data locality and reduce overall execution time.
Finally, there is a plenty of small improvements that can be made in the node stealing algorithm in order to
get better scalability.

\section{Third Major Goal: Compilation and Runtime Improvements}

The third goal is to improve the absolute running time of LM programs. While some programs fair very well against slower languages such as Python,
there's still some work that can be done to make \lang more competitive. \lang programs can take advantage of the fact that
\lang is logic-based language and thus it is possible to optimize and simplify the execution of rules
if we prove that facts follow certain properties and constraints.

Although compiled \lang programs are byte-code interpreted, which is a natural
source of overhead, we think this is still the best architecture for our system and the overhead
is on the na\"{\i}ve compilation of programs. However, 
if some rules use a lot of mathematical or list operations it may be worth trying to compile them into machine code instead of using interpreted byte-code.

To better understand the sources of overhead of our virtual machine, we propose doing a series
of experiments to understand where the most execution time is spent. We will gather the following
items:

\begin{itemize}
   \item \textbf{Database search operations}
   
   Measure the time spent fetching or searching facts from the database.
   
   \item \textbf{Database insertion/removal operations}
   
   Measure the time spent inserting and removing facts into the database.
   
   \item \textbf{Rule measurement}
   
   Measure the time spent executing each rule of the program.
   
   \item \textbf{Fact statistics}
   
   Measure the number of facts derived and consumed for each predicate.
   
   \item \textbf{Communication overhead}
   
   Measure the communication overhead between threads.

   \item \textbf{Priority information}

   Collect information about the use of coordination directives and their effect on the runtime in terms of number of facts proved and rules derived.
\end{itemize}

The sequential execution of LM programs can be further improved by using invariant optimizations.
By this, we mean proving certain properties about the program and its facts and then compiling the program accordingly.

\begin{itemize}
   
   \item \textbf{Property facts}
   
   In most programs there is a set of linear facts that act as a field of the node. These facts may
   be consumed and derived but they are never consumed because only their arguments change.
   For example:

\begin{Verbatim}
a(A, X), b(A, X) -o a(A, Y).
\end{Verbatim}

   In this case we consume \texttt{a(A, X)} but we derive another \texttt{a(A, Y)} with a different
   second argument. We want to prove that, for certain predicates, at any point in time there is only one
   set of facts of that predicate and although they may be consumed, only the arguments change.
   With this analysis, we can improve the code to avoid unnecessary re-derivations.
   
   \item \textbf{Triggering linear facts}
   
   Some facts never really trigger the execution of rule, because most rules need one or two special facts that
   will activate the rule. Those facts are derived in only a few rules and are intermittently consumed and
   re-derived. All the non-triggering facts never activate the execution of rules because they may be
   property facts and are constantly present in the database.
   We must prove which predicates potentially trigger the execution of rules and mark them as such.
   
   \item \textbf{Single use facts}
   
   Single use facts are a special case of triggering linear facts because once they are derived they are
   proven to be immediately consumed. The following example shows the only place in the program where
   the \texttt{a/2} predicate is used in the body of the rule. Note that no matter what the state of
   the database is, we can prove that \texttt{a/2} facts can be used immediately and work as a function
   call in imperative languages.
   
   \begin{Verbatim}
   .... -o a(A, 2).

a(A, 1) -o ....
a(A, 2) -o ....
a(A, 3) -o ....

   ....
   \end{Verbatim}
    
\end{itemize}

Note that these are only preliminary invariant optimizations. More optimization ideas will appear
as we look further into our programs and find general patterns.

\section{Fourth Major Goal: Measurements}

After implementing all the needed optimizations, we want to measure the effect of each optimization
and relate each program to the optimizations used.

Finally we want to systematically compare \lang execution against execution of the identical programs
in languages such as C, Python, Haskell and Prolog. While we do not expected to run as fast as C,
\lang programs should be very competitive against Python, Haskell and Prolog. This is very important, since
if the sequential execution is competitive enough, then running the program in parallel will
easily beat such languages.

\section{Optional Goal: Program Correctness}

Some work has already been done to prove properties of linear logic programs.
Robert Simmons employed an approach called generative invariants~\cite{simmons:Thesis} to prove that an operational semantics of a programming
language follows some invariants, namely type preservation. It may be possible to extend such approach to
prove several invariants about our programs, including correctness invariants.

If the time allows, we also want to write correctness and termination proofs for some of the implemented \lang programs.

\section{Planned Schedule}

The proposed work is scheduled on a 12 month timeline ending May 2015.

\begin{itemize}
   \item \textbf{Summer 2014}
   
   Measure the sources of overhead of the virtual machine and apply the required optimizations to fix them.

   Improve the scalability of current coordination mechanisms and write a few more programs using coordination
   directives. Meanwhile extend the set of coordination directives that will help implement the new programs.

   \textbf{Checkpoint}: new LM programs and benchmarks.
   
   \item \textbf{Fall 2014}
   
   Design a set of invariant optimizations and implement them in the compiler. Meanwhile, benchmark the runtime of programs to see how they improve the execution.
   
   Continue working on scalability optimizations.
   Build website for \lang and then make \lang publicly available.
   
   \textbf{Checkpoint}: The \lang website. Improved benchmark results for \lang programs.
   
   \item \textbf{Spring 2015}
   
   Write the thesis document.
   
   \textbf{Checkpoint}: thesis defense.

\end{itemize}

