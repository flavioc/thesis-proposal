We next give an overview of the related work including declarative languages, programming models
based on graphs, linear logic, coordination and provability.

\subsection{Declarative Programming}

Many programming models have been developed in order to make parallel programs both easier to write and reason about. The most famous examples of such paradigms are \emph{logic programming} and \emph{functional programming}.
In logic languages such as Prolog, researchers took advantage of the non-determinism of proof-search to evaluate subgoals
in parallel with models such as \emph{or-parallelism} and \emph{and-parallelism}~\cite{Gupta:2001:PEP:504083.504085}.
In functional languages, the stateless nature of computation allows multiple expressions to evaluate safely in parallel.
This has been initially explored in several languages, such as NESL~\cite{Blelloch:1996:PPA:227234.227246} or Id~\cite{Nikhil93anoverview}, and later implemented in more modern languages such as Haskell~\cite{Chakravarty07dataparallel}.

Recently, there has been an increasing interest in declarative and data-centric languages.
MapReduce~\cite{Dean:2008:MSD:1327452.1327492}, for instance, is a popular data-centric programming
model that is optimized for large clusters. The scheduling and data sharing model is very simple:
in the \emph{map phase}, data is transformed at each node and the result reduced to a final
result in the \emph{reduce phase}.

Another declarative approach that is regaining popularity is Datalog~\cite{Ullman:1990:PDK:533142}, a
bottom-up logic programming language that was the inspiration for the original Meld.
Traditionally used in deductive databases, it is now being increasingly used in different fields
such as distributed networking~\cite{Loo-condie-garofalakis-p2}, sensor
nets~\cite{Chu:2007:DID:1322263.1322281} and cloud computing~\cite{alvaro:boom}.

\subsection{Graph-Based Programming Models}

Like Meld, many programming systems also model the program as a graph where computation will be performed.
The Dryad system~\cite{Isard:2007:DDD:1272996.1273005} combines computational vertices
with communication channels (edges) to form a data-flow graph. The program is scheduled to
run on multiple computers or cores and data is partitioned during runtime. Routines that run on computational vertices
are sequential, with no synchronization.

The Pregel system~\cite{Malewicz:2010:PSL:1807167.1807184} is also graph based, although programs have a more strict
structure. They must be represented as a sequence of iterations where each iteration is composed of computation and message passing.
Pregel is specially suited to solve very big graphs
and to scale to large architectures.

GraphLab~\cite{GraphLab2010} is a C++ framework for developing parallel machine learning
algorithms. While Pregel uses message passing, GraphLab allows nodes to have read/write
access to different scopes through different concurrent access models in order to balance
performance and data consistency. While some programs only need to access the local node's
data, others may need to update edge information. Each consistency model will provide different
guarantees that are better adapted to some algorithms. GraphLab also provides different
schedulers that dictate the order in which node's are computed.

\subsection{Linear Logic}

Linear logic is a substructural logic proposed by Jean-Yves Girard~\cite{Girard95logic:its} that extends intuitionistic logic with the concept of \emph{truth as resources}. Instead of seeing the truth as immutable, truth is now something that can be consumed during the proof process.

Since computer science is focused on processes and algorithms, linear logic has been used
in many areas of computing such as programming languages, game semantics, concurrent programming, knowledge representation, etc.
Due to the resource interpretation of the logic, linear logic presents a good basis for programming
languages that allow state manipulation.

In the context of the Curry-Howard correspondence~\cite{howard:tfatnoc}, linear logic has been applied in programming languages
as a mechanism to implement \emph{linear types}. Linear types or also sometimes known as \emph{uniqueness types} are types
that force objects to be used exactly once. Surprisingly, such types add mutable state to functional languages because they enforce
a linear view of state, allowing the language to naturally support concurrency, input/output and data structure's updates.
Arguably, the most popular language that features uniqueness types is the Clean programming language~\cite{JFP:1349748}.
Monads~\cite{Wadler:1997:DI:262009.262011}, made popular with the Haskell programming language, are another interesting way to add state
to functional languages. While monads tend to be more powerful than linear types, they also ensure equational reasoning in the presence
of mutable data structures and I/O effects.

As we will see in the next chapters of this proposal, linear logic programming is a different approach than either monads or linear types.
While the latter are mechanisms that enhance functional programming with state, the former uses state as a foundation, since
the program's database is both the state and the program, because it drives the computation forward through rule application. However, our
new language can also interact with the outside world through sensing and action facts, which are special facts that return information
about the world and act on the outside world, respectively.

\subsection{Coordination}

Many programming languages follow what is called the coordination paradigm~\cite{Papadopoulos98coordinationmodels}. This form of distributed
programming divides execution in two parts: computation, where the actual computation is performed, and
coordination, which deals with communication and cooperation between processing units. This paradigm attempts to clearly distinguish between
these two parts by providing abstractions for coordination in an attempt to provide architecture and system-independent forms of communication.

We can identify two main types of coordination models:

\begin{description}
   \item[Data-Driven:] In a data-driven model,
the state of the computation depends on both the data being received or transmitted by the processes and the current configuration
of the coordinated processes. The coordinated process is not only responsible for reading and manipulating the data but is also
responsible for coordinating itself and/or other processes. Each process must intermix the coordination directives provided by the coordination
model with the computation code. While these directives have a very clear interface, it is in the programmer's responsibility to use them correctly.

   \item[Task-Driven:] In this model, the coordination code is more cleanly separated from the computation code. While in data-driven models, the content of the data exchanged by the processes will affect how the processes coordinate with each other, in a task-driven model, the process behavior depends only on the coordination patterns that are setup before hand. This means that the computation component is defined as a black box and there are clearly defined interfaces for input/output. These interfaces are usually defined as a full-fledged coordination language and not as
   simple directives present in the data-driven models.
\end{description}

Linda~\cite{linda} is probably the most famous coordination model. Linda implements a data-driven coordination model
and features a \emph{tuple space} that can be manipulated using the following coordination directives: \texttt{out(t)}
writes a tuple \texttt{t} into the tuple space; \texttt{in(t)} reads a tuple using the template \texttt{t}; \texttt{rd(t)} retrieves
a copy of the tuple \texttt{t} from the tuple space; and \texttt{eval(p)} puts a process \texttt{p} in the tuple space and executes it in parallel.
Linda processes do not need to know the identity of other processes because processes only communicate through the tuple space.
Linda can be implemented on top of many popular languages by simply creating a communication and storage mechanism for the tuple space
and then adding the directives as a language library.

The original Meld~\cite{ashley-rollman-iclp09} can also be seen as a kind of data-driven coordination language. The important distinction is that
in Meld there's no explicit coordination directives. When Meld rules are activated they may derive facts that need to be sent to a neighboring robot. In turn, this will activate computation on the neighbor. Robot communication is implemented by \emph{localizing} the program rules
and then by creating \emph{communication rules}.

The proposed LM language also implements communication rules, however it goes further because
some facts, action facts, can change how the processing units schedule nodes to be executed, namely, which node is to be computed next, which may in turn change
the program's final result. This result in a more complete inter-play between coordination code and data.

\subsection{Provability}

Many techniques and formal systems have been devised to help reason about parallel programs.
One such example is the Owicki-Gries~\cite{Owicki:1976:VPP:360051.360224} deductive system
for proving properties about imperative parallel programs (deadlock detection, termination, etc).
It extends Hoare logic with a stronger set axioms such as parallel execution, critical section
and auxiliary variables. The formal system can be successfully used in small imperative
programs, although using it on languages such as C is difficult since they do not
restrict the use of shared variables.

Some formal systems do not build on top of a known programming paradigm, but instead
create an entirely new formal system for describing concurrent systems. Process calculus
such as $\pi$-calculus~\cite{Milner:1999:CMS:329902} is a good example of this.
The $\pi$-calculus describes the interactions between processes
through the use of channels for communication. Interestingly, channels can also be transmitted as
messages, allowing for changes in the network of processes.
Given two processes, $\pi$-calculus is able to prove that they behave the same through
the use of bisimulation equivalence.

Another interesting model is Mobile UNITY~\cite{Roman97anintroduction}. The basic UNITY~\cite{UNITY} model assumes that statements could be executed non-deterministically
in order to create parallelism. This principle is applied to prove properties about
the system.
Mobile UNITY transforms UNITY by adding locations to processes and removing the
nondeterministic aspect from local processes. Processes could then communicate or move
between locations.

Since the original Meld is based on logic programming, it has been used to produce proofs of correctness.
Meld program code is amenable to mechanized analysis via theorem checkers such as Twelf~\cite{twelf},
a logic system designed for analyzing program logics and logic program implementations.
For instance, a meta-module based shape planner program was proven to be correct~\cite{dewey-iros08,ashley-rollman-iclp09}
under the assumption that actions derived by the program are always successfully applied in the outside world.
While the fault tolerance aspect is lax, the planner will always reach the target shape in finite time.
The sketch of the proof is presented in Dewey et al~\cite{dewey-iros08}.