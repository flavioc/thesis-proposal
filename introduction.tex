
The last decade has seen a priority shift for processor manufactures. If clock frequency
was once the main metric for performance, today computing power is measured in number of
cores in a single chip.
For software developers and computer scientists, once focused in developing sequential programs,
newer hardware usually meant faster programs without any change to the source code. Today,
the free lunch is over. Multicore processors are now forcing the development of
new software methodologies that take advantage of increasing processing power through parallelism.
However, parallel programming is difficult, usually because programs are written
in imperative and stateful programming languages that make use of low level synchronization
primitives such as locks, mutexes and barriers. This tends to make the task of managing multithreaded
execution quite intricate and error-prone, resulting in race hazards and deadlocks.
In the future, \emph{many-core} processors will make this task look even more daunting.

Advances in network speed and bandwidth are making distributed computing
more appealing. For instance, \emph{cloud computing} is a new emerging paradigm that wants
to make every computer connected to the Internet as a part of a pool of computing power,
where data can be retrieved and computation performed. From the perspective of high performance
computing, the \emph{computer cluster} is a well established paradigm that uses fast local area
networks to improve performance and solve problems that would take a long time with a single computer.

Developments in parallel and distributed programming have given birth to several programming models.
At one end of the spectrum are lower-level programming abstractions such as
\emph{message passing} (e.g., MPI~\cite{gabriel04-open-mpi}) and \emph{shared memory}
(e.g., Pthreads~\cite{Butenhof:1997:PPT:263953} or OpenMP~\cite{Chapman-2007-UOP-1370966}).
While such abstractions are very expressive and enable the programmer to write high performant code,
program APIs are very hard to use and debug, which makes it difficult to prove that a program is correct.
On the opposite end, we have many declarative programming models
that can be run in parallel~\cite{Blelloch:1996:PPA:227234.227246}.
While those declarative paradigms tend to make programs easier to reason about, they tend to offer
little or no control to the programmer for managing parallel execution
which may result in suboptimal performance.

In the context of the Claytronics project~\cite{goldstein-computer05}, Ashley-Rollman et al.~\cite{ashley-rollman-iclp09, ashley-rollman-derosa-iros07wksp}
has created Meld, a logic programming language suited to program massively distributed systems made of modular robots with a dynamic topology.
Meld programs can derive actions that are used
to make the robots act on the outside world. The distribution of computation is done
by first partitioning the program state across the robots and then making the computation local to the node. Because Meld programs
are sets of logical clauses, they are more amenable to proof.

However, Meld and other declarative programming models give very little control to the programmer since they are stateless languages.
This is a clear disadvantage against lower-level abstractions, since its difficult to change how programs are scheduled by
the runtime system and how the system manages parallelism.

In this proposal, we present Linear Meld (LM), a new language for parallel programming that extends the
original Meld with linear logic. Linear logic gives the language a structured
way to manage state, allowing the programmer to derive and delete logical facts.
While the new language retains the declarative aspects of Meld due to the introduction of linear logic, but also adds explicit programmer control and opportunities for optimization that arise with stateful programs.
We reuse the concept of action facts, present in the original Meld, in order to pass scheduling decisions to
the runtime system. We intend to introduce opportunities for program optimization, improved data partitioning and
parallel scheduling by using the same logical code used for standard computation.

In particular, we are interested in efficiently executing graph-based algorithms on multicores. The original Meld is a good
starting point because it sees a distributed program as a network of processing units, therefore
there is a naturally mapping to these kinds of algorithms.

\section{Thesis Statement}

\input{statement}

